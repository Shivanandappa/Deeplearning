{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68dab6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e6b8a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/aishwaryajayanth/Downloads/Aalen/DL/Examples/uk_utils'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7ae2e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/aishwaryajayanth/Downloads/Aalen/DL/Dataset/my/archive/Admission_Predictt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea13b06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bf81f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3aac6811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         500 non-null    int64  \n",
      " 1   GRE Score          500 non-null    int64  \n",
      " 2   TOEFL Score        500 non-null    int64  \n",
      " 3   University Rating  500 non-null    int64  \n",
      " 4   SOP                500 non-null    float64\n",
      " 5   LOR                500 non-null    float64\n",
      " 6   CGPA               500 non-null    float64\n",
      " 7   Research           500 non-null    int64  \n",
      " 8   Chance of Admit    500 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 35.3 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed145544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5a43e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['Serial No.'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47b4ea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,0:-1]\n",
    "y = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68fc15ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>332</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>337</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>330</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>327</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0          337          118                  4  4.5   4.5  9.65         1\n",
       "1          324          107                  4  4.0   4.5  8.87         1\n",
       "2          316          104                  3  3.0   3.5  8.00         1\n",
       "3          322          110                  3  3.5   2.5  8.67         1\n",
       "4          314          103                  2  2.0   3.0  8.21         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "495        332          108                  5  4.5   4.0  9.02         1\n",
       "496        337          117                  5  5.0   5.0  9.87         1\n",
       "497        330          120                  5  4.5   5.0  9.56         1\n",
       "498        312          103                  4  4.0   5.0  8.43         0\n",
       "499        327          113                  4  4.5   4.5  9.04         0\n",
       "\n",
       "[500 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78fcf9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.92\n",
       "1      0.76\n",
       "2      0.72\n",
       "3      0.80\n",
       "4      0.65\n",
       "       ... \n",
       "495    0.87\n",
       "496    0.96\n",
       "497    0.93\n",
       "498    0.73\n",
       "499    0.84\n",
       "Name: Chance of Admit , Length: 500, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27e4e673",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "460cf3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>310</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>318</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>300</td>\n",
       "      <td>101</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>300</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>322</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>307</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>321</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>326</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>300</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "238        310          104                  3  2.0   3.5  8.37         0\n",
       "438        318          110                  1  2.5   3.5  8.54         1\n",
       "475        300          101                  3  3.5   2.5  7.88         0\n",
       "58         300           99                  1  3.0   2.0  6.80         1\n",
       "380        322          104                  3  3.5   4.0  8.84         1\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "255        307          110                  4  4.0   4.5  8.37         0\n",
       "72         321          111                  5  5.0   5.0  9.45         1\n",
       "396        325          107                  3  3.0   3.5  9.11         1\n",
       "235        326          111                  5  4.5   4.0  9.23         1\n",
       "37         300          105                  1  1.0   2.0  7.80         0\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf96067d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304    0.62\n",
       "340    0.75\n",
       "47     0.89\n",
       "67     0.57\n",
       "479    0.79\n",
       "       ... \n",
       "11     0.84\n",
       "192    0.86\n",
       "92     0.34\n",
       "221    0.75\n",
       "110    0.61\n",
       "Name: Chance of Admit , Length: 100, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a57413bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64de9011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4       , 0.42857143, 0.5       , ..., 0.57142857, 0.50320513,\n",
       "        0.        ],\n",
       "       [0.56      , 0.64285714, 0.        , ..., 0.57142857, 0.55769231,\n",
       "        1.        ],\n",
       "       [0.2       , 0.32142857, 0.5       , ..., 0.28571429, 0.34615385,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.7       , 0.53571429, 0.5       , ..., 0.57142857, 0.74038462,\n",
       "        1.        ],\n",
       "       [0.72      , 0.67857143, 1.        , ..., 0.71428571, 0.77884615,\n",
       "        1.        ],\n",
       "       [0.2       , 0.46428571, 0.        , ..., 0.14285714, 0.32051282,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ab838ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90e4ed84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-01 20:42:33.380168: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-05-01 20:42:33.380256: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Architecture of neural network\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(7,activation='relu',input_dim=7))\n",
    "model.add(Dense(7,activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96da892e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 8         \n",
      "=================================================================\n",
      "Total params: 120\n",
      "Trainable params: 120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad34a163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model \n",
    "model.compile(loss='mean_squared_error',optimizer='Adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7c121bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-01 20:42:34.182196: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-05-01 20:42:34.182399: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-05-01 20:42:40.410505: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 8s 26ms/step - loss: 0.3763 - val_loss: 0.3641\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3162 - val_loss: 0.3019\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2629 - val_loss: 0.2472\n",
      "Epoch 4/100\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2045"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-01 20:42:42.394056: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2025 - val_loss: 0.1994\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1629 - val_loss: 0.1533\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1244 - val_loss: 0.1091\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0857 - val_loss: 0.0713\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0544 - val_loss: 0.0497\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0385 - val_loss: 0.0406\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0344 - val_loss: 0.0356\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0317 - val_loss: 0.0318\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0284 - val_loss: 0.0283\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0265 - val_loss: 0.0249\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0220 - val_loss: 0.0217\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0212 - val_loss: 0.0191\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0190 - val_loss: 0.0169\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0162 - val_loss: 0.0151\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0147 - val_loss: 0.0136\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.0124\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0112\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0106 - val_loss: 0.0104\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0109 - val_loss: 0.0096\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0095 - val_loss: 0.0088\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.0082\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.0077\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0087 - val_loss: 0.0073\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0071\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0077 - val_loss: 0.0067\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0070 - val_loss: 0.0063\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0060\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0063 - val_loss: 0.0060\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0063 - val_loss: 0.0056\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0056\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0066 - val_loss: 0.0053\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0064 - val_loss: 0.0052\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0050\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0061 - val_loss: 0.0049\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0062 - val_loss: 0.0051\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0049\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0061 - val_loss: 0.0048\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0047\n"
     ]
    }
   ],
   "source": [
    "plot_history= model.fit(X_train_scaled,y_train,epochs=100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7700e501",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-01 20:42:47.154344: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50a82b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7752478911680655"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score #r2  (coefficient of determination) regression score function.\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7e03c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x17d1d6ac0>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(plot_history.history['loss'])\n",
    "plt.plot(plot_history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56027e51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
